# Conversational-ai-papers
In this seminar, we will explore the fundamentals of conversational AI, from understanding the underlying technologies to hands-on demonstrations of building chatbot applications.



| Title | Paper / Resource | Year | Why is it interesting? | Asignee | Recording | Slides 
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Large Languague Models|[GPT2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), [GPT4](https://arxiv.org/pdf/2303.08774.pdf), [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf)| 2023 | <details><summary>read why</summary> A review of the greatest and latest LLMs.</details> |  [@ganitk]() |[zoom](https://us02web.zoom.us/rec/share/lOWh16ywt38XsO0Qvu7hFspH3GdbwuHKjcHbK8wq_KPCWBIEkT3wx5pysTEIghfe.QYIy3nzeWgOkDs5y)(oY$3#=&W)|[slides](https://docs.google.com/presentation/d/19GRB92ckNENT_ENMfA2Ct8fU2GXxFn7ugxHa_BBjEZg/edit?pli=1#slide=id.p) |
|Large Languague Models|[Llama 2](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)| 2023 | <details><summary>read why</summary> A review of the greatest and latest LLMs.</details> |  [@Tal Ben Haim]() |[zoom](https://us02web.zoom.us/rec/share/dQfnZRAEutgABQNkIIZsHXuLflSxy3tRkhU3zgicUGs9jnaE-R3PR51gLMflRda_.l_c9u43O2MusRZaT)(cH?85a^6)|[slides](https://docs.google.com/presentation/d/1Ma0mg0s8K564QM9b3Kb6woy5m6GJnU6pWrwCuKNhRJA/edit?usp=sharing) |
|Hands-on vectorDB (pinecode)|[Vector db summary](https://www.pinecone.io/learn/vector-database/), [Code example](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/gpt4-retrieval-augmentation/gpt-4-langchain-docs.ipynb#scrollTo=p0U9_7Fium8u)| 2023 | <details><summary>read why</summary> A short turtorial of how to use open source libraries to retrive documents. </details> |  [Self-work]() |[zoom](TBD)(code)|[slides](TBD)|
|LangChain & AutoGPT|[Introduction to langchain](https://python.langchain.com/docs/get_started/introduction.html), [AutoGPT](https://autogpt.net/)| 2023 | <details><summary>read why</summary> A turtorial on the latest and greatest apis for conversational ai. </details> |  [@Sagi]() |[zoom](TBD)(code)|[slides](TBD) |
|Adapter models|[K-adapters](https://arxiv.org/pdf/2002.01808.pdf), [AdapterHub](https://arxiv.org/pdf/2007.07779.pdf)| 2020 | <details><summary>read why</summary> Model specialization technique which trains only small components on top of the existing model layers.  </details> |  [@Shira]() |[zoom](TBD)(code)|[slides](TBD) |
|Parameter-efficient fine-tuning (PEFT)|[LoRA](https://arxiv.org/pdf/2106.09685.pdf), [QLoRA](https://github.com/artidoro/qlora), [AdaLoRA](https://arxiv.org/pdf/2303.10512.pdf)| 2021 - 2023 | <details><summary>read why</summary> Fine-tune technique that do not require full model finetuning. The idea behind LoRA is that fine-tuning a foundation model on a downstream task does not require updating all of its parameters. There is a low-dimension matrix that can represent the space of the downstream task with very high accuracy.  </details> |  [@Mengi]() |[zoom](TBD)(code)|[slides](TBD) |
|Retrieval-Augmented Language Modeling (RALM)|[In-Context Retrieval-Augmented Language Models](https://arxiv.org/pdf/2302.00083.pdf)| 2023 | <details><summary>read why</summary> A method for incoporating the retrived documents for the generation process of the LM </details> |  [AI21 Presenter]() |[zoom](TBD)(code)|[slides](TBD) |
